{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\nagem\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "#import some libraries\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from typing import List\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble, cluster\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords # library \n",
    "nltk.download('stopwords')\n",
    "all_stopwords = set(stopwords.words('english')) # set the language \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\nagem\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "# #remove stop-words\n",
    "# from nltk.corpus import stopwords # library \n",
    "# nltk.download('stopwords')\n",
    "# all_stopwords = set(stopwords.words('english')) # set the language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "review  sentiment\n0               ðŸ’œðŸ’œðŸ’œ          5\n1  Pls make it th13          3\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          sentiment\ncount  50001.000000\nmean       4.612628\nstd        1.026489\nmin        1.000000\n25%        5.000000\n50%        5.000000\n75%        5.000000\nmax        5.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50001.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.612628</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.026489</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#load datset\n",
    "df = pd.read_csv('C:/Users/nagem/OneDrive/Documents/MSBA 2019/570/clash_of_clans_570/clash-of-clans.csv')\n",
    "reviews_data = pd.DataFrame({'review': df.Content, 'sentiment': df.Rating})\n",
    "print(reviews_data.head(2))\n",
    "\n",
    "# reading review data with panda frames \n",
    "reviews_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was loaded and 2 columns were kept, the one with reviews and the sentiment score which was on a scale of 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode non-anscii to anscii and then decode string\n",
    "reviews_data['review'] = reviews_data['review'].apply(lambda x: str(x).encode('ascii','ignore').decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews had some non-anscii characters which had to be encoded and decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "I hated film It disaster Poor bad acting\n"
    }
   ],
   "source": [
    "# The sentiments are either 'positive' or 'negative' and are evenly distributed. Lets preprocess the text using the simple tokenizer we built in last class. We call it preprocess_text now.\n",
    "def preprocess_text(text):\n",
    "    pattern1 = re.compile(\"<br /><br />|\\.\")\n",
    "    lines = re.split(pattern1, text)\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        tokens += line.split(\" \")\n",
    "\n",
    "    # lowercase and remove any non-alphanumeric characters from tokens for normalize\n",
    "    normalized_tokens = [token for token in tokens if re.search(r\"^[A-Za-z]\\w*$\", token) is not None]\n",
    "    return  \" \".join([\n",
    "            token\n",
    "            for token in normalized_tokens\n",
    "            if token and token not in all_stopwords and len(tokens) > 1\n",
    "        ])\n",
    "    \n",
    "\n",
    "  \n",
    "custom_review = \"I hated the film. It was a disaster. Poor direction, bad acting.\"\n",
    "custom_review_tokens = preprocess_text(custom_review)\n",
    "print(custom_review_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews were cleaned and split into words. Normalization removed punctuation and stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply preprocessing to review data\n",
    "reviews_data['review'] = reviews_data['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_count_thr = 1000 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "\n",
    "vectorizer=TfidfVectorizer(min_df=lower_count_thr,max_df=upper_count_thr,binary=False,ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialy the TfidVectorizer was tried with a lower threshold of 1000 and an upper count of 5000. The ngram_range was set to (1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = vectorizer.fit_transform(reviews_data['review'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "50001\n    awesome  best       coc  ever  great   it     like  love  much  play  \\\n10      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n11      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n12      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n13      0.0   0.0  0.000000   0.0    0.0  0.0  0.64249   0.0   0.0   0.0   \n14      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n15      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n16      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n17      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n18      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n19      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n20      0.0   0.0  0.000000   0.0    1.0  0.0  0.00000   0.0   0.0   0.0   \n21      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   1.0   0.0   0.0   \n22      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n23      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n24      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n25      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n26      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n27      0.0   0.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n28      0.0   1.0  0.000000   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n29      0.0   0.0  0.694754   0.0    0.0  0.0  0.00000   0.0   0.0   0.0   \n\n    please  super  supercell  this  time  very     world  \n10     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n11     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n12     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n13     0.0    0.0   0.766294   0.0   0.0   0.0  0.000000  \n14     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n15     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n16     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n17     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n18     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n19     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n20     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n21     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n22     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n23     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n24     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n25     0.0    1.0   0.000000   0.0   0.0   0.0  0.000000  \n26     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n27     0.0    0.0   0.000000   0.0   1.0   0.0  0.000000  \n28     0.0    0.0   0.000000   0.0   0.0   0.0  0.000000  \n29     0.0    0.0   0.000000   0.0   0.0   0.0  0.719247  \n"
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df[10:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clust = 3\n",
    "km = KMeans(n_clusters = num_clust, max_iter=100, n_init=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n       n_clusters=3, n_init=1, n_jobs=None, precompute_distances='auto',\n       random_state=None, tol=0.0001, verbose=0)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "km.fit(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\nCluster 0:\n love\n much\n coc\n play\n best\n supercell\n like\n it\n awesome\n great\nCluster 1:\n best\n like\n very\n it\n play\n time\n ever\n great\n super\n coc\nCluster 2:\n this\n best\n love\n play\n world\n awesome\n like\n ever\n time\n much\n"
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(num_clust):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting clusters were very positive and somewhat similar sounding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizer\n",
    "def run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter=100, n_init=1): \n",
    "    vectorizer=TfidfVectorizer(min_df=lower_count_thr,max_df=upper_count_thr,binary=False,ngram_range=(n_gram_min,n_gram_max))\n",
    "\n",
    "    tfidf_vectors = vectorizer.fit_transform(reviews)\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = tfidf_vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "    # print('Length of denselist:\\n', len(df))\n",
    "    # print('#10-30 from denselist:\\n',df[10:30])\n",
    "\n",
    "    km = KMeans(n_clusters = num_clust, max_iter=max_iter, n_init=n_init)\n",
    "\n",
    "    km.fit(tfidf_vectors)\n",
    "\n",
    "    print(\"Top terms per cluster:\")\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(num_clust):\n",
    "        print(\"\\nCluster %d:\" % i),\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind]),\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function was created to run multiple Kmeans with one cell that had adjustable parameters. Different variations were tried to see which would result in useful clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n much\n like\n love\n time\n this\n play\n loved\n it\n very\n supercell\n\nCluster 1:\n very\n this\n it\n play\n super\n time\n great\n awesome\n please\n amazing\n\nCluster 2:\n love\n coc\n this\n clash\n play\n playing\n clans\n awesome\n it\n really\n\nCluster 3:\n like\n play\n this\n coc\n it\n love\n really\n games\n pubg\n time\n\nCluster 4:\n best\n ever\n world\n this\n played\n the\n it\n strategy\n coc\n pubg\n"
    }
   ],
   "source": [
    "lower_count_thr = 500 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 1\n",
    "n_gram_max = 1\n",
    "reviews = reviews_data['review']\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since and overwhelming percentage of reviews were 5 star and had similar words, the lower and upper threshold were lowered to captured more unique words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n addictive\n fun\n really\n killer\n strategy\n graphics\n its\n playing\n so\n amazing\n\nCluster 1:\n amazing\n games\n fun\n the\n its\n update\n clash\n played\n interesting\n app\n\nCluster 2:\n cool\n its\n fun\n so\n really\n games\n addictive\n amazing\n graphics\n app\n\nCluster 3:\n pubg\n fantastic\n better\n mobile\n clash\n playing\n boring\n games\n played\n amazing\n\nCluster 4:\n bad\n not\n pubg\n so\n update\n id\n lost\n download\n boring\n give\n"
    }
   ],
   "source": [
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 1000 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 1\n",
    "n_gram_max = 1\n",
    "reviews = reviews_data['review']\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n time\n killer\n pass\n great\n upgrade\n play\n waste\n best\n long\n much\n\nCluster 1:\n love\n coc\n much\n this\n clash\n best\n clans\n play\n very\n awesome\n\nCluster 2:\n it\n best\n world\n interesting\n play\n love\n like\n awesome\n great\n amazing\n\nCluster 3:\n really\n fun\n love\n like\n great\n play\n addictive\n it\n this\n playing\n\nCluster 4:\n best\n very\n like\n this\n super\n ever\n awesome\n play\n world\n great\n"
    }
   ],
   "source": [
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 1\n",
    "n_gram_max = 1\n",
    "reviews = reviews_data['review']\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments with different number of ngrams were tested to see if more information could be interpreted from the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n amazing\n amazing game\n game amazing\n this\n it\n love\n this game\n its\n play\n wow\n\nCluster 1:\n good game\n very good\n very\n it good\n it\n this good\n this\n play\n game play\n game good\n\nCluster 2:\n nice game\n like\n very\n this\n it\n super\n awesome\n great\n play\n time\n\nCluster 3:\n love\n love game\n game love\n much\n game much\n this\n nice game\n play\n this game\n app\n\nCluster 4:\n best\n best game\n ever\n game ever\n world\n game world\n played\n this best\n ever played\n this\n"
    }
   ],
   "source": [
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 1\n",
    "n_gram_max = 2\n",
    "reviews = reviews_data['review']\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n nice game\n so\n its\n game nice\n ever\n game ever\n really\n wow\n graphics\n it\n\nCluster 1:\n best\n best game\n this\n very\n it\n super\n play\n awesome\n time\n great\n\nCluster 2:\n like\n like game\n game like\n much\n like much\n game much\n good game\n play\n coc\n this\n\nCluster 3:\n good game\n very good\n very\n it good\n it\n this good\n this\n game play\n play\n game good\n\nCluster 4:\n love\n love game\n game love\n much\n game much\n this\n nice game\n play\n app\n this game\n"
    }
   ],
   "source": [
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 5000 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 1\n",
    "n_gram_max = 2\n",
    "reviews = reviews_data['review']\n",
    "max_iter = 200\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Top terms per cluster:\n\nCluster 0:\n very good game\n it good game\n love game much\n best strategy game\n this game good\n this best game\n the best game\n this good game\n like game much\n it best game\n\nCluster 1:\n best game world\n this best game\n it best game\n game best game\n the best game\n this game best\n love game much\n like game much\n this good game\n very good game\n\nCluster 2:\n very nice game\n game love game\n game best game\n best game world\n like game much\n best strategy game\n game ever played\n it best game\n it good game\n it nice game\n\nCluster 3:\n game ever played\n best strategy game\n this best game\n the best game\n it best game\n game best game\n this game best\n game love game\n like game much\n best game world\n\nCluster 4:\n world best game\n best game world\n this game best\n this best game\n game best game\n it good game\n very good game\n game ever played\n love game much\n very nice game\n"
    }
   ],
   "source": [
    "lower_count_thr = 100 # rare words/tokens\n",
    "upper_count_thr = 800 # frequent/common tokens\n",
    "num_clust = 5\n",
    "n_gram_min = 3\n",
    "n_gram_max = 3\n",
    "reviews = reviews_data['review']\n",
    "max_iter = 200\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length rating1:  2877\nLength rating2:  583\nLength rating3:  1398\nLength rating4:  3316\nLength rating5:  41827\n"
    }
   ],
   "source": [
    "rating1 = reviews_data[reviews_data['sentiment']==1]['review']\n",
    "print('Length rating1: ', len(rating1))\n",
    "\n",
    "rating2 = reviews_data[reviews_data['sentiment']==2]['review']\n",
    "print('Length rating2: ', len(rating2))\n",
    "\n",
    "rating3 = reviews_data[reviews_data['sentiment']==3]['review']\n",
    "print('Length rating3: ', len(rating3))\n",
    "\n",
    "rating4 = reviews_data[reviews_data['sentiment']==4]['review']\n",
    "print('Length rating4: ', len(rating4))\n",
    "\n",
    "rating5 = reviews_data[reviews_data['sentiment']==5]['review']\n",
    "print('Length rating5: ', len(rating5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews were then separated into groups based on rating and clusters made of each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3 2589\nTop terms per cluster:\n\nCluster 0:\n worst game\n good game\n this game\n nice game\n play game\n supercell id\n game ever\n waste time\n boring game\n clash clans\n\nCluster 1:\n bad game\n very bad game\n very bad\n bad game world\n game play\n game world\n this bad\n game time\n playing game\n slow loading\n\nCluster 2:\n best game\n game world\n worst game world\n worst game\n world best\n good game\n game pubg\n game best game\n world best game\n game best\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.9) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 3\n",
    "n_gram_min = 2\n",
    "n_gram_max = 4\n",
    "reviews = rating1\n",
    "max_iter = 200\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one star rating had a large amount of negative words and some positive. Of the three clusters above, two were related to supercell sugesting this may be a factor in disatisfied users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 2302\nTop terms per cluster:\n\nCluster 0:\n worst game ever\n very good game\n pubg better coc\n game ever played\n worst game world\n time wasting game\n it good game\n worst game ever played\n clan war league\n very bad game\n\nCluster 1:\n th new hero\n need th new\n need th new hero\n game there thought game\n game thank devs\n game thank devs ruining\n game thank you\n game thats unfair\n game the game\n game the game look\n\nCluster 2:\n very bad game\n zyada boring hai seriously\n game th bye bye\n game th lev qwit\n game th12 coming\n game thank devs\n game thank devs ruining\n game thank you\n game thats unfair\n game the game\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0005) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.8) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 3\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating1\n",
    "max_iter = 200\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hypothesized that the majority of reviews in any rating category would be farely generic so further lowered the threshold  in hopes of capturing more unique and descriptive words. When the cluster focused more on rare words and use ngram of (3,4), we began to see some interesting things come out. In the clusters above, the cluster 0 seems to have pretty generic negative reviews. For cluster 1, one of the commonly repeated thems is devs, suggesting the players blame the developers for the negative state of the game. Cluster 2 references the tropps and battles with the emphasis on how unpredictable of inconsistent they were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3 1295\nTop terms per cluster:\n\nCluster 0:\n clan war league\n worst game world\n super cell id\n it good game\n very good game\n clash clans game\n remove supercell id\n this game bad\n the worst game\n game worst game\n\nCluster 1:\n worst game ever\n worst game ever played\n game ever played\n game ever play\n the worst game\n this game worst\n game worst game\n google play sign\n game love game\n it good game\n\nCluster 2:\n time wasting game\n would give stars\n it is so\n it good game\n it bad game\n is so bad\n id much upgraded face\n id much upgraded\n google play sign\n google play game\n\nCluster 3:\n very bad game\n bad game world\n bad game bad\n waste of time\n google play game\n it nice game\n it is so\n it good game\n it bad game\n is so bad\n\nCluster 4:\n pubg better coc\n would give stars\n google play game\n it nice game\n it is so\n it good game\n it bad game\n is so bad\n id much upgraded face\n id much upgraded\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.45) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 5\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating1\n",
    "max_iter = 50\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A somewhat frequent occurance in the last few clusters was mention of google or google play. There maybe some aspect of google play that is causing users to have a bad experience. Another common occurance references \"id much upgraded\" or \"id much upgraded face\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 292\nTop terms per cluster:\n\nCluster 0:\n consuming lot battery\n add flag pakistan\n wow brilliant game\n cheat lol bad\n this game stupid\n need good grapics\n no update halloween\n my troops showing\n not bad good\n this good game\n\nCluster 1:\n graphics update bro game\n need bang graphics update\n know attacking booring\n know attacking booring takes\n attacking booring takes much\n attacking booring takes\n become booring know attacking\n become booring know\n booring know attacking\n booring know attacking booring\n\nCluster 2:\n make short time searching\n short time searching\n please make short\n short time searching opponent\n make short time\n please make short time\n time searching opponent\n period please make\n can make weekly\n can make weekly period\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.5) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 3\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating2\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 466\nTop terms per cluster:\n\nCluster 0:\n consuming lot battery\n add flag pakistan\n nice game coments\n itry first timer\n sooooo good game\n days login app\n this good game\n acc lock hours\n it fuk game\n single mb update\n\nCluster 1:\n upon stronger player keep\n getting beat weak player\n players getting beat weak\n higher rank battle\n higher rank battle pro\n pray upon stronger player\n pray upon stronger\n getting beat weak\n people know place\n battle pro players getting\n\nCluster 2:\n new update lengthy processes\n new update lengthy\n update lengthy processes\n zuerst bestimmte gebude bauen\n game successfully installed\n game starting hve edton\n game starting someone\n game starting someone may\n game stoped loading\n game stoped loading plz\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.8) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 3\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating2\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the two star reviews, we see a some different topics occuring. In the clusters above, cluster 0 references money which may be related to the game requiring players to spend money in order to get better weapons. They are able to achieve it but it takes a very long time. cluster 2 references how long it takes to achieve nakakawala, again related to the time required to get certain things without spending money. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 1118\nTop terms per cluster:\n\nCluster 0:\n this good game\n best game ever\n very nice game\n world best game\n nice game time\n best strategic game\n good pubg best\n good game like\n good strategic game\n time pass game\n\nCluster 1:\n very good game\n very good game love\n good game love\n zwischen truppe und fertig\n get banned we said\n get easy clan games\n get easy clan\n get damaged heavily make\n get damaged heavily\n get clan war builder\n\nCluster 2:\n game please developed\n like game please\n like game please developed\n zwischen truppe und fertig\n get account misguided\n get enough loot upgrade\n get enough loot\n get easy clan games\n get easy clan\n get damaged heavily make\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.8) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 3\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating3\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 3 stars we start to see more positive sentiment again. In the above clusters, cluster 0 has pretty positive sentiment. Cluster 1 seems to talk about difficulties getting enough loot. Cluster 2 appears to be related to users that felt the main had become stale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 839\nTop terms per cluster:\n\nCluster 0:\n game good game\n nice game good\n nice game good game\n think game good\n big problem game\n think game good game\n updates slow big\n updates slow big problem\n liyas think game\n liyas think game good\n\nCluster 1:\n very good game\n this good game\n best game ever\n very nice game\n world best game\n nice game time\n best strategic game\n good pubg best\n good game like\n time pass game\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0001) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.6) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 2\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating3\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another clustering of 3 start reviews had a class related to progress restart of deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 1118\nTop terms per cluster:\n\nCluster 0:\n hoping something boost\n the game dead still\n hoping something boost activity\n something boost activity\n something boost activity people\n boost activity people game\n boost activity people\n still love hoping\n activity people game\n dead still love hoping\n\nCluster 1:\n very good game\n this good game\n very nice game\n world best game\n best strategic game\n good pubg best\n good game like\n time pass game\n good strategic game\n nice game addictive\n\nCluster 2:\n best game ever\n zwischen truppe und fertig\n get clan war builder\n get far takes forever\n get far takes\n get enough loot upgrade\n get enough loot\n get easy clan games\n get easy clan\n get damaged heavily make\n\nCluster 3:\n nice game time\n get clan war\n get far takes forever\n get far takes\n get enough loot upgrade\n get enough loot\n get easy clan games\n get easy clan\n get damaged heavily make\n get damaged heavily\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0005) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.8) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 4\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating3\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cluster 3 there are references to when connection was very bad during Christmas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 909\nTop terms per cluster:\n\nCluster 0:\n very good game\n best game ever\n good game like\n this good game\n it good game\n very nice game\n overall good game\n world best game\n good pubg best\n good game time\n\nCluster 1:\n clan war league\n written maintaining break\n experience good lost account\n good game like\n good game but\n gmail account pls help\n gmail account pls\n give new update change\n give new update\n getting really bored waiting\n\nCluster 2:\n this game good\n game good time\n written maintaining break\n games take forever\n good game like\n good game but\n gmail account pls help\n gmail account pls\n give new update change\n give new update\n\nCluster 3:\n like game much\n this good game\n written maintaining break\n game would play\n good game like\n good game but\n gmail account pls help\n gmail account pls\n give new update change\n give new update\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0015) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.65) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 4\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating3\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the clusters above, we again see gmail account mentioned. There may be issues that users are experiencing related to google or gmail accounts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 1326\nTop terms per cluster:\n\nCluster 0:\n best game ever\n very good game\n very nice game\n this good game\n its good game\n best game world\n game ever played\n this game nice\n good time pass\n good game play\n\nCluster 1:\n good game many\n it good game\n game many players\n its good game\n give gems hours\n game time pass game\n gave stars if\n games especially children child\n games especially children\n game would like\n\nCluster 2:\n great time killer\n good strategy game\n nice game play\n would great could\n game time pass game\n games especially children child\n games especially children\n game would like\n game would better\n game upgrade time\n\nCluster 3:\n it good game\n it good game play\n good game play\n good game new\n good game option\n want change name\n good game people\n good game need\n good game like\n it best game\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0005) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.4) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 4\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating4\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the 4 star ratings, we seem to have more positive sentiment than the previous ratings. Two new topics also appear. One refers to children and the other to dark or gold elixir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2 995\nTop terms per cluster:\n\nCluster 0:\n very nice game\n best game world\n very good game\n it good game\n this best game\n love game much\n world best game\n best strategy game\n this game good\n best game ever\n\nCluster 1:\n great game love\n its great game love\n great game love supercell\n great game love playing\n great game love much\n game love playing\n game love supercell\n its great game\n game love much\n game love really\n\nCluster 2:\n best game ever\n best game ever played\n game ever played\n the best game ever\n the best game\n this best game ever\n this best game\n game ever played life\n ever played life\n one best game ever\n\nCluster 3:\n my favourite game\n game it awesome\n love game my\n people download game\n favourite game loved\n favourite game pubg\n game played android\n game play years\n game play time\n game play this\n"
    }
   ],
   "source": [
    "lower_count_thr = round(len(reviews)*.0005) # rare words/tokens\n",
    "upper_count_thr = round(len(reviews)*.3) # frequent/common tokens\n",
    "print(lower_count_thr, upper_count_thr)\n",
    "num_clust = 4\n",
    "n_gram_min = 3\n",
    "n_gram_max = 4\n",
    "reviews = rating5\n",
    "max_iter = 100\n",
    "n_init = 5\n",
    "\n",
    "run_kmeans(lower_count_thr, upper_count_thr, num_clust, n_gram_min, n_gram_max, reviews, max_iter, n_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5 star ratings were very positive in tone and did not provide much information on details about things that people liked or things that could be improved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this research was in part to determine features of the game that players either liked or did not like so the developers could make improvements in those areas. \n",
    "\n",
    "* From one star ratings we see that players are likely unhappy about unpredictable troops and battle. \n",
    "* Two star reviews feel negatively about how long it takes to get further in the game without spending money. \n",
    "* For three star reviews the clusters suggest that players are having issue with their gmail or google play accounts. \n",
    "* Four star reviews reference dark or gold elixir it is seen with references to better and children. \n",
    "* The five star reviews did not seem to reference specific as the other ratings did. However, these were the majority of the reviews which suggests the game is well liked and negative things mentioned in lower star reviews do not greatly impact the majority of players badly. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}